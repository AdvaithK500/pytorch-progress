{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0fb156",
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "\n",
    "def dijkstra1(adjacency_matrix, start):\n",
    "\n",
    "    n = len(adjacency_matrix)\n",
    "    V = [i for i in range(n)]\n",
    "    d = {node: float('inf') for node in V}\n",
    "    pi = {node: None for node in V}\n",
    "    visited = set()\n",
    "    d[start] = 0\n",
    "\n",
    "    while len(visited) < n:\n",
    "        # Find nearest unvisited node\n",
    "        unvisited = [i for i in range(n) if i not in visited]  # Initialise array for priority queue\n",
    "        nearest = min(unvisited, key=lambda node: d[node])    \n",
    "\n",
    "        # Visit the node\n",
    "        visited.add(nearest)\n",
    "        # Update distance to neigbours\n",
    "        for i in range(n):\n",
    "            w = adjacency_matrix[nearest][i]\n",
    "            if w != 0 and w != float('inf') and i not in visited:\n",
    "                if d[nearest] + w < d[i]:\n",
    "                    d[i] = d[nearest] + w\n",
    "                    pi[i] = nearest\n",
    "\n",
    "    return d, pi \n",
    "\n",
    "\n",
    "def dijk_minheap(adjacency_list, start):\n",
    "    n = len(adjacency_list)\n",
    "    d = {node: float('inf') for node in range(n)}\n",
    "    pi = {node: None for node in range(n)}\n",
    "    d[start] = 0\n",
    "    visited = set()\n",
    "\n",
    "    q = [(0, start)]\n",
    "    \n",
    "    while len(visited) < n:\n",
    "        min_length, nearest = heapq.heappop(q)\n",
    "        visited.add(nearest)\n",
    "        \n",
    "        if min_length > d[nearest]:\n",
    "            continue\n",
    "        else:\n",
    "            for i, w in adjacency_list[nearest]:\n",
    "                if d[nearest] + w < d[i]:\n",
    "                    d[i] = d[nearest] + w\n",
    "                    pi[i] = nearest\n",
    "                    heapq.heappush(q, (d[i], i))\n",
    "\n",
    "    return d, pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584cd4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def generateInputMatrix_v(v, prob):\n",
    "    \n",
    "    edge = 0\n",
    "    matrix = [[float('inf') for _ in range(v)] for _ in range(v)]\n",
    "\n",
    "    for i in range(v):\n",
    "        for j in range(v):\n",
    "            if i == j:\n",
    "                matrix[i][j] = 0\n",
    "            elif matrix[i][j] == float('inf'):\n",
    "                if random.random() < prob:\n",
    "                    matrix[i][j] = random.randint(1, 50)\n",
    "                    edge += 1\n",
    "                \n",
    "    return edge, matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e32cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def generateInputArray(v, prob):\n",
    "\n",
    "    edge = 0\n",
    "    adj_lists = [[] for _ in range(v)]\n",
    "\n",
    "    for i in range(v):\n",
    "\n",
    "        for j in range(v):\n",
    "            if i == j:\n",
    "                continue\n",
    "            elif random.random() < prob:\n",
    "                node = j\n",
    "                adj_lists[i].append((node, random.randint(1, 50)))\n",
    "                edge += 1\n",
    "\n",
    "    return edge, adj_lists\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bccc6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertMatrixToList(matrix):\n",
    "    adj_lists = [[] for _ in range(len(matrix))]\n",
    "    for i in range(len(matrix)):\n",
    "        for j in range(len(matrix)):\n",
    "            if matrix[i][j] != 0 and matrix[i][j] != float('inf'):\n",
    "                adj_lists[i].append((j, matrix[i][j]))\n",
    "    return adj_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedc81bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "v_values = [100, 1000, 2000, 5000, 10000, 20000]\n",
    "cpu_times = []\n",
    "edge_values = []\n",
    "density = 1\n",
    "\n",
    "for v in v_values:\n",
    "    edges, matrix = generateInputMatrix_v(v, density)\n",
    "    edge_values.append(edges)\n",
    "    start_time = time.perf_counter()\n",
    "    d, pi = dijkstra1(matrix, 0)\n",
    "    end_time = time.perf_counter()\n",
    "    cpu_times.append(end_time - start_time)\n",
    "\n",
    "# Plot results\n",
    "plt.plot(v_values, cpu_times, marker=\"o\")\n",
    "plt.xlabel(\"# of Vertices (V)\")\n",
    "plt.ylabel(\"CPU Time (s)\")\n",
    "plt.title(f\"Dijkstra (a), Density = {density}\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(edge_values, cpu_times, marker=\"o\")\n",
    "plt.xlabel(\"# of Edges (E)\")\n",
    "plt.xscale('log')\n",
    "plt.ylabel(\"CPU Time (s)\")\n",
    "plt.title(f\"Dijkstra (a), Density = {density}\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0f48ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "v_values = [100, 1000, 2000, 5000, 10000, 20000]\n",
    "cpu_times = []\n",
    "edge_values = []\n",
    "density = 1\n",
    "\n",
    "for v in v_values:\n",
    "    edges, lists = generateInputArray(v, density)\n",
    "    edge_values.append(edges)\n",
    "    start_time = time.perf_counter()\n",
    "    d, pi = dijk_minheap(lists, 0)\n",
    "    end_time = time.perf_counter()\n",
    "    cpu_times.append(end_time - start_time)\n",
    "\n",
    "# Plot results\n",
    "plt.plot(v_values, cpu_times, marker=\"o\")\n",
    "plt.xlabel(\"# of Vertices (V)\")\n",
    "plt.ylabel(\"CPU Time (s)\")\n",
    "plt.title(f\"Dijkstra (b), Density = {density}\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(edge_values, cpu_times, marker=\"o\")\n",
    "plt.xlabel(\"# of Edges (E)\")\n",
    "plt.xscale('log')\n",
    "plt.ylabel(\"CPU Time (s)\")\n",
    "plt.title(f\"Dijkstra (b), Density = {density}\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9191b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "densities = [0.2, 0.5, 1]\n",
    "v_values = [100, 1000, 2000, 5000, 10000, 20000]\n",
    "\n",
    "for density in densities:\n",
    "    cpu_times_a = []\n",
    "    cpu_times_b = []\n",
    "    for v in v_values:\n",
    "        edges, matrix = generateInputMatrix_v(v, density)\n",
    "        adj_list = convertMatrixToList(matrix)\n",
    "        start_time = time.perf_counter()\n",
    "        d, pi = dijkstra1(matrix, 0)\n",
    "        end_time = time.perf_counter()\n",
    "        cpu_times_a.append(end_time - start_time)\n",
    "        start_time = time.perf_counter()\n",
    "        d, pi = dijk_minheap(adj_list, 0)\n",
    "        end_time = time.perf_counter()\n",
    "        cpu_times_b.append(end_time - start_time)\n",
    "\n",
    "    fig, ax1 = plt.subplots()\n",
    "    ax1.set_xlabel('# of Vertices (V)')\n",
    "    ax1.set_ylabel('CPU Times (s)', color='blue')\n",
    "    ax1.plot(v_values, cpu_times_a, 'o-', color='blue', label=\"(a)\")\n",
    "    ax1.plot(v_values, cpu_times_b, 's--', color='red', label=\"(b)\")\n",
    "   \n",
    "    plt.title(f'Dijkstra (a) vs (b), Density = {density}')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8dfc7ea-2d3f-4a73-84e8-5f5861fb09e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_PATH\"] = r\"C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.8\"\n",
    "import cupy as cp\n",
    "print(\"CuPy version:\", cp.__version__)\n",
    "print(\"CUDA root path:\", cp.cuda.get_cuda_path())\n",
    "print(\"GPU:\", cp.cuda.runtime.getDeviceProperties(0)['name'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90626f4d-3e9a-475f-be50-817b45040391",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Project_Xtreme\\pytorch-deep-learning\\env\\lib\\site-packages\\cupy\\_environment.py:215: UserWarning: CUDA path could not be detected. Set CUDA_PATH environment variable if CuPy fails to load.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown accelerator: nvrtc",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUPY_ACCELERATORS\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnvrtc\u001b[39m\u001b[38;5;124m\"\u001b[39m  \n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Optionally, if you built from source:\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# os.environ[\"CUDA_ARCH_LIST\"] = \"8.9\"   # or the arch code for your GPU\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcupy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcp\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Print device properties\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCuPy version:\u001b[39m\u001b[38;5;124m\"\u001b[39m, cp\u001b[38;5;241m.\u001b[39m__version__)\n",
      "File \u001b[1;32mC:\\Project_Xtreme\\pytorch-deep-learning\\env\\lib\\site-packages\\cupy\\__init__.py:16\u001b[0m\n\u001b[0;32m     12\u001b[0m _environment\u001b[38;5;241m.\u001b[39m_preload_library(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcutensor\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# NOQA\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 16\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcupy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _core  \u001b[38;5;66;03m# NOQA\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'''\u001b[39m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124m================================================================\u001b[39m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;132;01m{\u001b[39;00m_environment\u001b[38;5;241m.\u001b[39m_diagnose_import_error()\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;124m================================================================\u001b[39m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;124m'''\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Project_Xtreme\\pytorch-deep-learning\\env\\lib\\site-packages\\cupy\\_core\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# mypy: ignore-errors\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcupy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_core\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m core  \u001b[38;5;66;03m# NOQA\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcupy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_core\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m fusion  \u001b[38;5;66;03m# NOQA\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcupy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_core\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m internal  \u001b[38;5;66;03m# NOQA\u001b[39;00m\n",
      "File \u001b[1;32mcupy\\\\_core\\\\core.pyx:1\u001b[0m, in \u001b[0;36minit cupy._core.core\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mcupy\\\\_core\\\\_kernel.pyx:1\u001b[0m, in \u001b[0;36minit cupy._core._kernel\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mcupy\\\\_core\\\\_accelerator.pyx:59\u001b[0m, in \u001b[0;36minit cupy._core._accelerator\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mcupy\\\\_core\\\\_accelerator.pyx:54\u001b[0m, in \u001b[0;36mcupy._core._accelerator._set_default_accelerators\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mcupy\\\\_core\\\\_accelerator.pyx:25\u001b[0m, in \u001b[0;36mcupy._core._accelerator.set_elementwise_accelerators\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mcupy\\\\_core\\\\_accelerator.pyx:20\u001b[0m, in \u001b[0;36mcupy._core._accelerator._get_accelerator\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown accelerator: nvrtc"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Force the environment so that your GPU arch is included / used\n",
    "os.environ[\"CUPY_ACCELERATORS\"] = \"nvrtc\"  \n",
    "# Optionally, if you built from source:\n",
    "# os.environ[\"CUDA_ARCH_LIST\"] = \"8.9\"   # or the arch code for your GPU\n",
    "\n",
    "import cupy as cp\n",
    "\n",
    "# Print device properties\n",
    "print(\"CuPy version:\", cp.__version__)\n",
    "print(\"GPU:\", cp.cuda.runtime.getDeviceProperties(0)['name'])\n",
    "print(\"Compute capability:\", cp.cuda.Device(0).compute_capability)\n",
    "\n",
    "# Try a minimal kernel to check that compilation works\n",
    "a = cp.arange(10, dtype=cp.float32)\n",
    "b = a * 2\n",
    "print(\"Test result:\", b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df99d44f-30ac-46a3-8c21-39b3dfc755dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d11eb89c-b10f-4b50-b322-ab054eb457de",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2344106506.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[6], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    pip uninstall -y cupy-cuda12x\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pip uninstall -y cupy-cuda12x\n",
    "pip install -U --pre cupy-cuda12x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae422fab-d1b8-4797-b4ea-9ba9d27d163f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GPU-accelerated Dijkstra...\n"
     ]
    },
    {
     "ename": "CUDADriverError",
     "evalue": "CUDA_ERROR_NO_BINARY_FOR_GPU: no kernel image is available for execution on the device",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCUDADriverError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 72\u001b[0m\n\u001b[0;32m     69\u001b[0m edge_values\u001b[38;5;241m.\u001b[39mappend(edges)\n\u001b[0;32m     71\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[1;32m---> 72\u001b[0m d_gpu \u001b[38;5;241m=\u001b[39m \u001b[43mdijkstra_gpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m cp\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mStream\u001b[38;5;241m.\u001b[39mnull\u001b[38;5;241m.\u001b[39msynchronize()\n\u001b[0;32m     74\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter() \u001b[38;5;241m-\u001b[39m start_time\n",
      "Cell \u001b[1;32mIn[5], line 39\u001b[0m, in \u001b[0;36mdijkstra_gpu\u001b[1;34m(adjacency_matrix, start)\u001b[0m\n\u001b[0;32m     36\u001b[0m n \u001b[38;5;241m=\u001b[39m adj\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     38\u001b[0m visited \u001b[38;5;241m=\u001b[39m cp\u001b[38;5;241m.\u001b[39mzeros(n, dtype\u001b[38;5;241m=\u001b[39mcp\u001b[38;5;241m.\u001b[39mbool_)\n\u001b[1;32m---> 39\u001b[0m dist \u001b[38;5;241m=\u001b[39m \u001b[43mcp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfull\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m dist[start] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n):\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;66;03m# Find nearest unvisited vertex (parallel argmin)\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Project_Xtreme\\pytorch-deep-learning\\env\\lib\\site-packages\\cupy\\_creation\\basic.py:327\u001b[0m, in \u001b[0;36mfull\u001b[1;34m(shape, fill_value, dtype, order)\u001b[0m\n\u001b[0;32m    325\u001b[0m         dtype \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(fill_value)\u001b[38;5;241m.\u001b[39mdtype\n\u001b[0;32m    326\u001b[0m a \u001b[38;5;241m=\u001b[39m cupy\u001b[38;5;241m.\u001b[39mndarray(shape, dtype, order\u001b[38;5;241m=\u001b[39morder)\n\u001b[1;32m--> 327\u001b[0m \u001b[43mcupy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopyto\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcasting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43munsafe\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    328\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m a\n",
      "File \u001b[1;32mC:\\Project_Xtreme\\pytorch-deep-learning\\env\\lib\\site-packages\\cupy\\_manipulation\\basic.py:97\u001b[0m, in \u001b[0;36mcopyto\u001b[1;34m(dst, src, casting, where)\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m src_is_scalar:\n\u001b[1;32m---> 97\u001b[0m     \u001b[43m_core\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43melementwise_copy\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _can_memcpy(dst, src):\n",
      "File \u001b[1;32mcupy\\\\_core\\\\_kernel.pyx:1374\u001b[0m, in \u001b[0;36mcupy._core._kernel.ufunc.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mcupy\\\\_core\\\\_kernel.pyx:1401\u001b[0m, in \u001b[0;36mcupy._core._kernel.ufunc._get_ufunc_kernel\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mcupy\\\\_core\\\\_kernel.pyx:1082\u001b[0m, in \u001b[0;36mcupy._core._kernel._get_ufunc_kernel\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mcupy\\\\_core\\\\_kernel.pyx:94\u001b[0m, in \u001b[0;36mcupy._core._kernel._get_simple_elementwise_kernel\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mcupy\\\\_core\\\\_kernel.pyx:82\u001b[0m, in \u001b[0;36mcupy._core._kernel._get_simple_elementwise_kernel_from_code\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mcupy\\\\_core\\\\core.pyx:2377\u001b[0m, in \u001b[0;36mcupy._core.core.compile_with_cache\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mC:\\Project_Xtreme\\pytorch-deep-learning\\env\\lib\\site-packages\\cupy\\cuda\\compiler.py:536\u001b[0m, in \u001b[0;36m_compile_module_with_cache\u001b[1;34m(source, options, arch, cache_dir, extra_source, backend, enable_cooperative_groups, name_expressions, log_stream, jitify)\u001b[0m\n\u001b[0;32m    532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _compile_with_cache_hip(\n\u001b[0;32m    533\u001b[0m         source, options, arch, cache_dir, extra_source, backend,\n\u001b[0;32m    534\u001b[0m         name_expressions, log_stream, cache_in_memory)\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 536\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile_with_cache_cuda\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    537\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43march\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_source\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    538\u001b[0m \u001b[43m        \u001b[49m\u001b[43menable_cooperative_groups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname_expressions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_stream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    539\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_in_memory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjitify\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Project_Xtreme\\pytorch-deep-learning\\env\\lib\\site-packages\\cupy\\cuda\\compiler.py:660\u001b[0m, in \u001b[0;36m_compile_with_cache_cuda\u001b[1;34m(source, options, arch, cache_dir, extra_source, backend, enable_cooperative_groups, name_expressions, log_stream, cache_in_memory, jitify)\u001b[0m\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    657\u001b[0m     \u001b[38;5;66;03m# we don't do any disk I/O\u001b[39;00m\n\u001b[0;32m    658\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m--> 660\u001b[0m \u001b[43mmod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcubin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    661\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mod\n",
      "File \u001b[1;32mcupy\\\\cuda\\\\function.pyx:263\u001b[0m, in \u001b[0;36mcupy.cuda.function.Module.load\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mcupy\\\\cuda\\\\function.pyx:265\u001b[0m, in \u001b[0;36mcupy.cuda.function.Module.load\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mcupy_backends\\\\cuda\\\\api\\\\driver.pyx:226\u001b[0m, in \u001b[0;36mcupy_backends.cuda.api.driver.moduleLoadData\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mcupy_backends\\\\cuda\\\\api\\\\driver.pyx:63\u001b[0m, in \u001b[0;36mcupy_backends.cuda.api.driver.check_status\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mCUDADriverError\u001b[0m: CUDA_ERROR_NO_BINARY_FOR_GPU: no kernel image is available for execution on the device"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# Dijkstra GPU-Only Implementation (CuPy)\n",
    "# ==========================================================\n",
    "\n",
    "import random\n",
    "import time\n",
    "import cupy as cp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -------------------------------\n",
    "# Input Generators\n",
    "# -------------------------------\n",
    "def generateInputMatrix_v(v, prob):\n",
    "    edge = 0\n",
    "    matrix = [[float('inf') for _ in range(v)] for _ in range(v)]\n",
    "    for i in range(v):\n",
    "        for j in range(v):\n",
    "            if i == j:\n",
    "                matrix[i][j] = 0\n",
    "            elif matrix[i][j] == float('inf'):\n",
    "                if random.random() < prob:\n",
    "                    matrix[i][j] = random.randint(1, 50)\n",
    "                    edge += 1\n",
    "    return edge, matrix\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# GPU: Dijkstra (Matrix-based with CuPy)\n",
    "# -------------------------------\n",
    "def dijkstra_gpu(adjacency_matrix, start):\n",
    "    \"\"\"\n",
    "    GPU-accelerated Dijkstra using CuPy.\n",
    "    Works efficiently for dense graphs represented as adjacency matrices.\n",
    "    \"\"\"\n",
    "    adj = cp.asarray(adjacency_matrix, dtype=cp.float32)\n",
    "    n = adj.shape[0]\n",
    "\n",
    "    visited = cp.zeros(n, dtype=cp.bool_)\n",
    "    dist = cp.full(n, cp.inf, dtype=cp.float32)\n",
    "    dist[start] = 0\n",
    "\n",
    "    for _ in range(n):\n",
    "        # Find nearest unvisited vertex (parallel argmin)\n",
    "        mask = cp.where(visited, cp.inf, dist)\n",
    "        u = int(cp.argmin(mask))\n",
    "        visited[u] = True\n",
    "\n",
    "        # Update all neighbors in parallel\n",
    "        new_dists = dist[u] + adj[u]\n",
    "        dist = cp.minimum(dist, new_dists)\n",
    "\n",
    "    cp.cuda.Stream.null.synchronize()  # wait for GPU\n",
    "    return cp.asnumpy(dist)\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# Run GPU Dijkstra + Plot Results\n",
    "# ==========================================================\n",
    "\n",
    "v_values = [100, 1000, 2000, 5000, 10000, 20000]   # Adjust as needed\n",
    "gpu_times = []\n",
    "edge_values = []\n",
    "density = 1.0\n",
    "\n",
    "print(\"Running GPU-accelerated Dijkstra...\")\n",
    "\n",
    "for v in v_values:\n",
    "    edges, matrix = generateInputMatrix_v(v, density)\n",
    "    edge_values.append(edges)\n",
    "\n",
    "    start_time = time.perf_counter()\n",
    "    d_gpu = dijkstra_gpu(matrix, 0)\n",
    "    cp.cuda.Stream.null.synchronize()\n",
    "    elapsed = time.perf_counter() - start_time\n",
    "    gpu_times.append(elapsed)\n",
    "\n",
    "    print(f\"V={v:<6d} | Edges={edges:<10d} | GPU Time={elapsed:.3f}s\")\n",
    "\n",
    "# ==========================================================\n",
    "# Plot Results\n",
    "# ==========================================================\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.plot(v_values, gpu_times, 'o-', label='GPU (CuPy)')\n",
    "plt.xlabel(\"# of Vertices (V)\")\n",
    "plt.ylabel(\"Time (s)\")\n",
    "plt.title(f\"Dijkstra GPU Performance (Density={density})\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.plot(edge_values, gpu_times, 's--', label='GPU (CuPy)')\n",
    "plt.xlabel(\"# of Edges (E)\")\n",
    "plt.xscale('log')\n",
    "plt.ylabel(\"Time (s)\")\n",
    "plt.title(f\"Dijkstra GPU Performance vs Edges (Density={density})\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
